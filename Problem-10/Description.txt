🧠 Problem Explanation
You are given a piece of text content (like a blog article). You need to:
    1. Ignore common stopwords like "the", "and", "is", etc.
    2. Ignore punctuation, so "word." becomes "word".
    3. Convert everything to lowercase to treat "Word" and "word" the same.
    4. Count how many times each remaining word appears.
    5. Find the most frequent word.
📚 Example
Input blog:
Text :"The sun shines over the lake. The lake is calm and beautiful. Sun is life."
Common stopwords:
stopwords = {'the', 'is', 'and', 'over'}
After cleaning:
    • Lowercase: "the sun shines over the lake. the lake is calm and beautiful. sun is life."
    • Remove punctuation: "the sun shines over the lake the lake is calm and beautiful sun is life"
    • Split into words:
['the', 'sun', 'shines', 'over', 'the', 'lake', 'the', 'lake', 'is', 'calm', 'and', 'beautiful', 'sun', 'is', 'life']
Remove stopwords:
['sun', 'shines', 'lake', 'lake', 'calm', 'beautiful', 'sun', 'life']
Count frequency:
    • sun: 2
    • lake: 2
    • shines: 1
    • calm: 1
    • beautiful: 1
    • life: 1
✅ Most frequent word:
    • "sun" or "lake" (both appear twice)

Stopword:
A stopword is a commonly used word that is often filtered out in natural language processing (NLP) tasks because it carries little meaningful information on its own. Examples include words like:
    • English: "the", "is", "in", "and", "of", "to", "a"
    • Bengali: "এবং", "এই", "একটি", "করে", "না", "তার"
Why remove stopwords?
In tasks like text classification, search engines, sentiment analysis, or topic modeling, removing stopwords:
    • Reduces the size of the data
    • Focuses on the more meaningful content
    • Improves computational efficiency


